{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf250
{\fonttbl\f0\fnil\fcharset0 Verdana;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green63\blue159;}
\margl1440\margr1440\vieww9000\viewh9000\viewkind0
\deftab720
\pard\pardeftab720\ql\qnatural

\f0\fs24 \cf0 Tim Blackman <br>\
3/27/2009 <br>\
('''status''' - ''complete'')\
\
==Introduction==\
\
Investigating ways to improve task scheduling by using information about\
data contention and data access patterns is a continuing area of\
research in Project Darkstar.  The current system provides the\
<tt>AccessCoordinator</tt> interface as the customization point that can\
be used to perform experiments with different approaches to detecting\
and managing data contention.  The design of write caching in the data\
service needs to continue to support these experiments while achieving\
good code modularity.\
\
==Customizing Contention Handling with the Access Coordinator==\
\
The access coordinator is designed to allow full customization of\
contention management, including detecting contention and deadlock,\
choosing deadlock victims, and deciding which blocked transactions to\
resume after a conflicting transaction completes.\
\
When implemented using a pessimistic algorithm for detecting contention,\
the access coordinator can choose, at the moment that an access is\
reported, to allow a single transaction to proceed with its access while\
blocking conflicting accesses.  When the current transaction completes,\
the access coordinator can choose which transaction or transactions\
should proceed next.  For optimistic schemes, the access coordinator can\
choose to permit multiple, potentially conflicting, transactions to\
proceed with their accesses.  At transaction preparation time, such a\
coordinator can check for actual conflicts and abort the transaction if\
needed.  Once the access coordinator confirms during preparation that a\
transaction has no conflicts, it needs to insure that no subsequent\
accesses by other transactions can introduce new conflicts prior to the\
end of the transaction.\
\
In addition to supporting different concurrency control schemes, having\
an independent access coordinator allows the system to support other\
sources of contention beyond the data service.  Because the facility for\
managing contention is independent of the data service, other components\
that produce contended access to shared items can also use the access\
coordinator to track accesses to their items.  The access coordinator\
can observe accesses generated by the multiple components, and make\
overall contention decisions accordingly.\
\
One consequence of managing contention in the access coordinator rather\
than as part of the implementation of the data cache is that the\
algorithm for making contention decisions will not know which items are\
present in the cache and which need to be retrieved via remote\
communication with the server.  That information could be useful for\
conflict or scheduling decisions, in particular if the access\
coordinator used previous access patterns of known tasks to predict\
which tasks might be able to run using currently cached data.  It might\
be possible to provide the access coordinator with information about\
caching by allowing the data service to support an optional interface\
for accessing information about cached items.\
\
Note that implementing conflict detection schemes in the access\
coordinator only allows it to control the way that local conflicts are\
handled, not conflicts that involve remote calls to the server.  When a\
data service operation requires write access, the access coordinator can\
choose to allow access to an item without enforcing exclusive access\
among local transactions.  If the write operation requires access to an\
object not available in the cache, though, then, because it does not\
know what sort of contention scheme the access coordinator employs, the\
cache will request write access to the item from the server.  If\
optimistic concurrency control is desired for non-local accesses, this\
behavior needs to be enabled by the data service, and is in fact already\
provided an option.  It would be useful to experiment with both scopes\
for optimistic concurrency to determine under which circumstances they\
are effective.\
\
==Considerations for Implementing the Data Cache==\
\
===Limited contention management in the data cache===\
\
With the data service relying on the access coordinator to manage data\
contention, the implementation of the data cache will show better\
modularity if it contains as little logic for handling contention as\
possible.  With this approach, the data cache would track the items held\
in the cache and the use of those items as a whole by local\
transactions, but without maintaining information about use by specific\
transactions or conflicts among local transactions.  In particular, it\
would be best to avoid the need to manage blocking for local conflicts\
accesses, instead leaving that responsibility to the access coordinator.\
The data cache should only need to block requests if the desired item is\
not available in the cache, or to prevent downgrading or evicting an\
item that is currently in use.  The data cache should be able to\
accomplish these goals by tracking the number, but not identity or\
dependencies, of current local readers and writers.\
\
===Contention during callbacks===\
\
When the data cache receives a callback request from the server to\
either downgrade or evict an item, the cache needs to determine whether\
it can satisfy the request immediately or must wait until the item is\
not in use.  If, when a request is received, the cache can lock the\
item's use count and determine that the item is not in use, then the\
cache can evict the item immediately.  While this procedure is underway,\
though, it is possible that a local transaction will report to the\
access coordinator an access to the item in the process of being\
evicted.  Since the cache's decision about whether an item is in use is\
made based on the use counts it maintains, independently of the access\
coordinator, the access coordinator will allow the local transaction's\
access attempt to succeed.  When the data service then attempts to\
obtain the item from the cache, it will find that it is no longer\
present, and will need to request it from the server.  This request may\
occur even while the item is still in the process of being evicted.  The\
data cache implementation will need to account for race conditions such\
as these, in particular to insure that the server prioritizes the new\
request for the item after processing its eviction and considering\
requests for access from other nodes.\
\
If the data cache finds that an item is in use at the time of a callback\
request, then the cache needs to delay servicing that request until the\
conflicting use is over, and any other pending local accesses have been\
satisfied.  In keeping with the idea of not building two facilities for\
managing conflicts, the data cache can use the access coordinator to\
handle this access request, much as local transactions do.\
\
===Contention during eviction===\
\
To support cache eviction, the data cache can rely on the in-use count\
information it maintains to determine which objects are currently in use\
and therefore not candidates for eviction.  Depending on the algorithm\
used to determine the best eviction candidate, there may be a delay\
between checking whether items are in use and attempting to evict the\
particular item selected as the best eviction candidate.  If during that\
delay a local transaction makes use of the selected item, the cache\
eviction algorithm will be unable to evict it, and has two choices.  One\
possibility is to rerun the selection algorithm to choose another\
candidate.  Since the previously selected item was just put in use, and\
the selection algorithm strives to select an item not recently used, it\
is unlikely that the same item will be selected next for eviction.  It\
is also unlikely that the new item will be used before it can be\
evicted.  So, although this approach runs the potential risk of making\
no forward progress, that risk is very slight.  Another possibility\
would be for the data cache to request access to the item from the\
access coordinator, and wait for that request to be satisfied before\
performing eviction or downgrading.\
\
===Multiple writes due to optimistic concurrency control===\
\
If the access coordinator implements optimistic concurrency control, it\
is possible that the data cache will observe multiple simultaneous write\
accesses for a given item.  The cache needs to track outstanding write\
accesses in order to determine if it can satisfy downgrade requests.  To\
maintain this information correctly, it should store separate counts for\
readers and writers.\
\
===Data cache modifications at commit time===\
\
The data cache needs to insure that modifications made at commit time\
are atomic and are performed in the correct order, to insure the\
integrity of transactions.  In the current implementation, the data\
service is the only durable participant, so it can rely on the fact that\
its <tt>prepareAndCommit</tt> method will be called.  As a result, the\
data service's commit operation will be completed before that of any\
other transaction participant.  If the access coordinator prevents\
conflicting modifications until its commit method is run, then the data\
service can rely on that to insure consistency.\
\
If the system were modified to support multiple durable transaction\
participants &mdash; a possible future goal &mdash; then other\
provisions would be needed.  One approach would be for the access\
coordinator to continue to prevent conflicting access until after the\
transaction commit was done, using the mechanism described below for\
notifications after transaction completion.  Another would be for the\
data store to perform its own synchronization.  Yet another approach\
would be for the data store to treat its queue of changes as a log to be\
consulted when supplying cached data values.  Note that, unlike a\
standard database transaction log, where disk flushes are known to be\
expensive, there is no particular reason to think that it will be time\
consuming to update data values in the cache.  For that reason, the\
complexity of reading pending updates from the log is probably not\
worthwhile.\
\
==Changes to the Data Service==\
\
===Moving access coordinator use to the data store===\
\
As currently implemented, the data service makes calls to the access\
coordinator directly.  Since the write caching scheme will be\
implemented within the data store, independent of the data service, and\
the data cache needs to make requests to access data in order to support\
blocking when handling callbacks, there needs to be some provision to\
support calls to the access coordinator by the data store.  One approach\
would be for the data service to document which access reporters and IDs\
it uses to report data accesses, and have the data store follow the same\
regimen.  Another approach would be to move all data access calls into\
the data store.  This second approach would avoid the need for the data\
service and data store to agree on this implementation detail.  It would\
also mean that the data store would continue to provide support for\
contention, making it easier to reason about and test.  To avoid the\
need for each data store implementation to provide its own\
implementation for interacting with the access coordinator, it would\
make sense to implement an abstract base class that provides this\
implementation behavior.\
\
\
\
===Data service checks for modified objects===\
\
The data service currently checks for objects that may have been\
modified during a transaction as part of its transaction preparation,\
and makes any needed modifications through the data store at that time.\
To insure that the access coordinator is aware at transaction\
preparation time of all data modifications being made in the\
transaction, some change is needed to insure that the data service's\
modifications are performed before the access coordinator's conflict\
check.  One way to do this would be for the transaction coordinator to\
have special knowledge of the ordering needs for these two transaction\
participants, so that it could insure that the access coordinator's\
prepare method was called after the data service's.  It seems like a\
poor modularity decision, though, for the these three independent\
components to have such a dependency on each other.\
\
Another approach is to introduce a facility for registering operations\
to be performed just prior to and just after a transaction finishes.\
J2EE includes a similar facility in the <tt>\
Synchronization</tt> interface, which is part of the Java\
Transaction API.  With such a facility in place, the data service could\
be changed to perform its modification checking and final data store\
updates just prior to the end of the transaction, so that the access\
coordinator could perform its validity checks during transaction\
preparation, knowing that all data store changes had been made.\
\
\pard\pardeftab720\ql\qnatural

\f1 \cf0 This material is distributed under the GNU General Public License Version 2. You may review the terms of this license at {\field{\*\fldinst{HYPERLINK "http://www.gnu.org/licenses/gpl-2.0.html"}}{\fldrslt \cf2 \ul \ulc2 http://www.gnu.org/licenses/gpl-2.0.html}}.\
To obtain a copy of the original source code, go to https://sgs-server.dev.java.net/svn/sgs-server/trunk/sgs-tutorial-server-doc and extract a copy of the file WriteCachingAccessCoord.rtf. \
\
Copyright \'a9 2009, 2010, Oracle and/or its affiliates. All rights reserved.
\f0 \
}